---
title: "Project bootstrap (100452273)"
author: "Laura Belizón Merchán, Jorge Lázaro Ruiz"
institute: "Simulation in Prob and Stats BSc AMC at UC3M"
date: "May 2024"
output:
  pdf_document:
    toc: true
    toc_depth: 2
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



# Introduction

The objective of this project is to design a model out of a collection of data on four variables: `y`, the response variable, and `x1`, `x2`, `x3`, the covariates that `y` is dependent on. Since the data contains outliers, we will resample our data using the bootstrap technique and make a robust linear regression model, removing a variable when we consider it not significant enough for our model.

As a note, this project was originally developed with a different dataset (100452172). However, with our chosen seed, no variables were insignificant in the model. Therefore, we changed to dataset 100452273 for a more complete case study.

<!--General explanation of the project with your own words. Include also a description of the type of bootstrap intervals that will be presented and a discussion of computational issues including code chunks with the functions that are specifically written to answer the questions (alternatively, present the code in an Appendix).-->

# Results

## CIs on the regression coefficientes for the initial model 

After importing the dataset and building a robust linear model, we perform 2000 iterations of the bootstrap method to estimate the coefficients of the model. The following shows the results of executing the code for Part 1 of Appendix A.

```{r ci-initial, echo=FALSE}
# Loading libraries
library(MASS)
library(bootstrap)

set.seed(1)

# Loading data
data <- read.csv("../data/data_100452273.csv")
nobs <- nrow(data) # No. of observations

# PART 1: Bootstrap resampling for robust linear regression model
# Build the RLM
maxit <- 50
rlm_model <- rlm(y ~ x1 + x2 + x3, data = data, maxit = maxit)
coef <- rlm_model$coefficients
coef_summary <- coef(summary(rlm_model))

# Bootstrap resampling
rrpair <- function(x, xdata) {
  rlm(y ~ x1 + x2 + x3, data = xdata[x, ], maxit = maxit)$coefficients # Extract coefficients
}

B <- 2000 # Number of bootstrap samples
estimates <- bootstrap(x = 1:nobs, nboot = B, theta = rrpair, xdata = data)$thetastar

# Calculate the CIs for each of the coefficients
ci_intercept <- 2 * coef['(Intercept)'] - quantile(estimates[1,], c(0.975, 0.025))
ci_x1 <- 2 * coef['x1'] - quantile(estimates[2,], c(0.975, 0.025))
ci_x2 <- 2 * coef['x2'] - quantile(estimates[3,], c(0.975, 0.025))
ci_x3 <- 2 * coef['x3'] - quantile(estimates[4,], c(0.975, 0.025))

# Combine the CIs into a table
boot_ci <- cbind(ci_intercept, ci_x1, ci_x2, ci_x3)
boot_ci # x3 is not significant because the 0 is contained in the CI
```

The data displayed in the table is are the basic bootstrap confidence intervals, which correspond to the following formula:

\[
  \left[ 2 \hat{\theta} - F_{\hat{\theta}^*}^{-1}(1 - \alpha / 2), 2 \hat{\theta} - F_{\hat{\theta}^*}^{-1}(\alpha / 2)  \right]
\]

With \(1 - \alpha\) as the confidence level, 0.95 in our case.

## Backward elimination procedure

As we can see, the coefficient for variable `x3` contains 0 in its confidence interval, so we can say that it is not a significant variable. Hence, we will remove it from the model in the following steps. This elimination is seen in Part 2 of Appendix A.

```{r, echo=FALSE}
# PART 2: Backward elimination
# Bootstrap resampling
rrpair <- function(x, xdata) {
  rlm(y ~ x1 + x2, data = xdata[x, ], maxit = maxit)$coefficients # Extract coefficients
}
rlm_model <- rlm(y ~ x1 + x2, data = data[, -4], maxit = maxit)
```

After eliminating `x3`, the confidence intervals for the coefficients of variables `x1` and `x2` do not contain 0 (as seen in the next section). Therefore, we stopped the backward elimination procedure and arrived to our final model.

## CIs on the regression coefficientes for the final model

We now show the aforementioned confidence interval for the coefficients of the new model without `x3`.

```{r, echo=FALSE}
# PART 3: Confidence intervals for the remaining variables
estimates <- bootstrap(x = 1:nobs, nboot = B, theta = rrpair, xdata = data[, -4])$thetastar
ci_intercept <- 2 * coef['(Intercept)'] - quantile(estimates[1,], c(0.975, 0.025))
ci_x1 <- 2 * coef['x1'] - quantile(estimates[2,], c(0.975, 0.025))
ci_x2 <- 2 * coef['x2'] - quantile(estimates[3,], c(0.975, 0.025))

boot_ci <- cbind(ci_intercept, ci_x1, ci_x2)

boot_ci # Both x1 and x2 are significant
```

##  CI(s) on the mean response



# References (not mandatory)

<!--Including textbooks, webpages, and class notes.-->

# Appendix A: Full code

## Part 1
```{r, eval=FALSE}
# Loading libraries
library(MASS)
library(bootstrap)

set.seed(1)

# Loading data
data <- read.csv("data/data_100452273.csv")
nobs <- nrow(data) # No. of observations

# PART 1: Bootstrap resampling for robust linear regression model
# Build the RLM
maxit <- 50
rlm_model <- rlm(y ~ x1 + x2 + x3, data = data, maxit = maxit)
coef <- rlm_model$coefficients
coef_summary <- coef(summary(rlm_model))

# Bootstrap resampling
rrpair <- function(x, xdata) {
  rlm(y ~ x1 + x2 + x3, data = xdata[x, ], maxit = maxit)$coefficients # Extract coefficients
}

B <- 2000 # Number of bootstrap samples
estimates <- bootstrap(x = 1:nobs, nboot = B, theta = rrpair, xdata = data)$thetastar

# Calculate the CIs for each of the coefficients
ci_intercept <- 2 * coef['(Intercept)'] - quantile(estimates[1,], c(0.975, 0.025))
ci_x1 <- 2 * coef['x1'] - quantile(estimates[2,], c(0.975, 0.025))
ci_x2 <- 2 * coef['x2'] - quantile(estimates[3,], c(0.975, 0.025))
ci_x3 <- 2 * coef['x3'] - quantile(estimates[4,], c(0.975, 0.025))

# Combine the CIs into a table
boot_ci <- cbind(ci_intercept, ci_x1, ci_x2, ci_x3)
boot_ci # x3 is not significant because the 0 is contained in the CI

```

## Part 2

```{r, eval=FALSE}
# PART 2: Backward elimination
# Bootstrap resampling
rrpair <- function(x, xdata) {
  rlm(y ~ x1 + x2, data = xdata[x, ], maxit = maxit)$coefficients # Extract coefficients
}
rlm_model <- rlm(y ~ x1 + x2, data = data[, -4], maxit = maxit)
```

## Part 3

```{r, eval=FALSE}
# PART 3: Confidence intervals for the remaining variables
estimates <- bootstrap(x = 1:nobs, nboot = B, theta = rrpair, xdata = data[, -4])$thetastar
ci_intercept <- 2 * coef['(Intercept)'] - quantile(estimates[1,], c(0.975, 0.025))
ci_x1 <- 2 * coef['x1'] - quantile(estimates[2,], c(0.975, 0.025))
ci_x2 <- 2 * coef['x2'] - quantile(estimates[3,], c(0.975, 0.025))

boot_ci <- cbind(ci_intercept, ci_x1, ci_x2)

boot_ci # Both x1 and x2 are significant
```

## Part 4

```{r, eval=FALSE}
# PART 4: Prediction
b_0 <- mean(boot_ci[, 1])
b_1 <- mean(boot_ci[, 2])
b_2 <- mean(boot_ci[, 3])
prediction <- b_0 + b_1 * 14 + b_2 * 14
print(prediction)
```